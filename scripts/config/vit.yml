# DATA:
img_size: 224
crop_pct: 0.875
data_dir: '/open_datasets/imagenet'
batch_size: 512
# MODEL:
TYPE: vit
model: 'vit_tiny_patch16_224'
drop: 0.1 # same as paper
model_kwargs: 
    patch_size: 16
    embed_dim: 192
    depth: 12
    num_heads: 3
    mlp_ratio: 4.0
    qkv_bias: true
    # drop_rate: 0.1 # same as paper, 等价于 drop
    attn_drop_rate: 0.1 # same as paper

# TRAIN:
epochs: 1 # same as paper
warmup_epochs: 0 # ~10k steps (4096 batch size)
weight_decay: 5e-4 # same as paper
lr_base: 1e-3
warmup_lr: 1e-6
min_lr: 0.0
clip_grad: 1.0
grad_accum_steps: 1
workers: 40

# OPTIMIZER:
opt: 'AdamW'
opt_betas: 
    - 0.9
    - 0.999
# opt_kwargs:
#     betas: (0.9, 0.999)

# NUM_EPOCHS: 300  # same as paper
# WARMUP_EPOCHS: 10  # ~10k steps (4096 batch size)
# WEIGHT_DECAY: 0.3  # same as paper
# BASE_LR: 3e-3
# WARMUP_START_LR: 1e-6
# END_LR: 0.0
# GRAD_CLIP: 1.0
# ACCUM_ITER: 16
# OPTIMIZER:
#     NAME: 'AdamW'
#     BETAS: (0.9, 0.999)
# VALIDATE_FREQ: 1
# SAVE_FREQ: 10
# REPORT_FREQ: 96
# QUANTIZE: False
amp: true
amp_impl: 'native'
use_multi_epochs_loader: true
pin_mem: true
pretrained: true

